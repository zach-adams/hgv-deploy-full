---

# See https://www.varnish-cache.org/docs/3.0/ for the official documentation

varnish_version: 3.0

# Specify the identity of the varnish server. This can be accessed using
# server.identity from VCL
varnish_identity: varnish

# Specify a name for this instance. Amonst other things, this name is used to
# construct the name of the directory in which varnishd keeps temporary files
# and persistent state. If the specified name begins with a forward slash, it is
# interpreted as the absolute path to the directory which should be used for
# this purpose.
varnish_instance_name: "{{varnish_identity}}"

varnish_conf_dir: "/etc/{{varnish_instance_name}}"
varnish_conf_file: "/etc/default/{{varnish_instance_name}}"  # FIXME: This is only valid for debians!
# Directory from which relative VCL filenames (vcl.load and include) are opened.
varnish_vcl_dir: "{{varnish_conf_dir}}"
# Directory where VCL modules are to be found.
varnish_vmod_dir: /usr/lib/varnish/vmods

# Write the process's PID to the specified file.
varnish_runtime_dir: /var/run
varnish_pid_file: "{{varnish_runtime_dir}}/{{varnish_instance_name}}.pid"

# Override this to provide your own VCL file
varnish_vcl: no


# Enables debugging mode: The parent process runs in the foreground with a CLI
# connection on stdin/stdout, and the child process must be started explicitly
# with a CLI command. Terminating the parent process will also terminate the
# child.
varnish_debug: no

# Run in background as a daemon.
varnish_daemonize: yes

# Specifies the names of the unprivileged user:group to which the child process
# should switch before it starts accepting connections.
varnish_user:
varnish_group:

varnish_environment: {}


# Interfaces
# -----------

# Use the specified host as backend server. If port is not specified, the
# default is 8080.
varnish_backend: 0.0.0.0:8080

# Listen for client requests on the specified addresses. The address can
# be a host name (“localhost”), an IPv4 dotted-quad (“127.0.0.1”), or an IPv6
# address enclosed in square brackets (“[::1]”). If address is not specified,
# varnishd will listen on all available IPv4 and IPv6 interfaces. If port is not
# specified, the default HTTP port as listed in /etc/services is used.
varnish_http_server: on
varnish_http_server_listen_on:
  - 0.0.0.0:80

# Offer a management interface on the specified address and port.
varnish_management_console: on
varnish_management_console_listen_on: 127.0.0.1:2000
# Path to a file containing a secret used for authorizing access to the
# management port.
varnish_management_console_secret_file:


# Common settings
# ---------------

# The following hash algorithms are available:
#
#   - simple_list:
#     A simple doubly-linked list. Not recommended for production use.
#
#   - classic[,buckets]:
#     A standard hash table. This is the default. The hash key
#     is the CRC32 of the object's URL modulo the size of the hash table. Each
#     table entry points to a list of elements which share the same hash key. The
#     buckets parameter specifies the number of entries in the hash table. The
#     default is 16383.
#
#   - critbit:
#     A self-scaling tree structure. The default hash algorithm in 2.1. In
#     comparison to a more traditional B tree the critbit tree is almost
#     completely lockless.
#
# See: https://www.varnish-cache.org/docs/3.0/reference/varnishd.html#hash-algorithms
varnish_hash_algorithm:
  type: classic
  options: ['16383']

# Use the specified list of storage backends. You can name the different
# backends. Varnish will then reference that backend with the given name in
# logs, statistics, etc.
#
# The following storage backends are available:
#
#   - malloc[,size]
#
#     Malloc is a memory based backend. Each object will be allocated from
#     memory. If your system runs low on memory swap will be used. Be aware that
#     the size limitation only limits the actual storage and that approximately
#     1k of memory per object will be used for various internal structures.
#
#     The size parameter specifies the maximum amount of memory varnishd will
#     allocate. The size is assumed to be in bytes, unless followed by one of
#     the following suffixes:
#
#       - K, k The size is expressed in kibibytes.
#       - M, m The size is expressed in mebibytes.
#       - G, g The size is expressed in gibibytes.
#       - T, t The size is expressed in tebibytes.
#
#     The default size is unlimited.
#
#     Mallocs performance is bound by memory speed so it is very fast.
#
#   - file[,path[,size[,granularity]]]
#
#     The file backend stores objects in memory backed by a file on disk with
#     mmap. This is the default storage backend and unless you specify another
#     storage this one will used along with Transient storage.
#
#     The path parameter specifies either the path to the backing file or the
#     path to a directory in which varnishd will create the backing file. The
#     default is /tmp.
#
#     The size parameter specifies the size of the backing file. The size is
#     assumed to be in bytes, unless fol‐ lowed by one of the following
#     suffixes:
#
#     K, k The size is expressed in kibibytes.
#     M, m The size is expressed in mebibytes.
#     G, g The size is expressed in gibibytes.
#     T, t The size is expressed in tebibytes.
#
#     % The size is expressed as a percentage of the free space on the
#     file system where it resides.
#     The default size is 50%.
#
#     If the backing file already exists, it will be truncated or expanded to
#     the specified size.
#
#     Note that if varnishd has to create or expand the file, it will not pre-
#     allocate the added space, leading to fragmentation, which may adversely
#     impact performance. Pre-creating the storage file using dd(1) will reduce
#     fragmentation to a minimum.
#
#     The granularity parameter specifies the granularity of allocation. All
#     allocations are rounded up to this size. The size is assumed to be in
#     bytes, unless followed by one of the suffixes described for size except
#     for %.
#
#     The default size is the VM page size. The size should be reduced if you
#     have many small objects.
#
#     File performance is typically limited by the write speed of the device,
#     and depending on use, the seek time.
#
#   - persistent,path,size *experimental*
#
#     Persistent storage. Varnish will store objects in a file in a manner that
#     will secure the survival of most of the objects in the event of a planned
#     or unplanned shutdown of Varnish.
#
#     The path parameter specifies the path to the backing file. If the file
#     doesn't exist Varnish will create it.
#
#     Varnish will split the file into logical silos and write to the silos in
#     the manner of a circular buffer. Only one silo will be kept open at any
#     given point in time. Full silos are sealed. When Varnish starts after a
#     shutdown it will discard the content of any silo that isn't sealed.
#
# For every storage backend, the size is assumed to be in bytes, unless followed
# by one of the following suffixes:
#
#     K, k The size is expressed in kibibytes.
#     M, m The size is expressed in mebibytes.
#     G, g The size is expressed in gibibytes.
#     T, t The size is expressed in tebibytes.
#
# See: https://www.varnish-cache.org/docs/3.0/reference/varnishd.html#storage-types
varnish_storage_backends:
  default:
    type: malloc
    options: ['{{ansible_memtotal_mb}}M']

# The storage backend named "Transient" will be used for transient (short lived)
# objects. By default Varnish uses an unlimited malloc backend for this.
varnish_transient_storage_backend:
  type: malloc
  options: []


# Logging
# -------

# Log the hash string components to shared memory log.
varnish_log_hashstring: on

# Log the local address on the TCP connection in the SessionOpen shared memory
# record.
varnish_log_local_address: off

# Maximum number of bytes in SHM log record. Maximum is 65535 bytes.
varnish_shm_reclen: 255

# Specify size of shmlog file. Scaling suffixes like 'k', 'm' can be used up to
# (e)tabytes. Default is 80 Megabytes. Specifying less than 8 Megabytes is
# unwise.
varnish_shmlog_size: 80M

# Bytes of shmlog workspace allocated for worker threads. If too big, it wastes
# some ram, if too small it causes needless flushes of the SHM workspace. These
# flushes show up in stats as "SHM flushes due to overflow". Minimum is 4096
# bytes.
varnish_shmlog_workspace: 8192

# Log all CLI traffic to syslog(LOG_INFO).
varnish_syslog_cli_traffic: on

# Trace VCL execution in the shmlog. Enabling this will allow you to see the
# path each request has taken through the VCL program. This generates a lot of
# logrecords so it is off by default.
varnish_vcl_trace: off


# Tuning
# ------

# Open files (usually 1024, which is way too small for varnish).
varnish_ulimit: 131072

# Maxiumum locked memory size for shared memory log.
varnish_memlock: 82000

# If we run out of resources, such as file descriptors or worker threads, the
# acceptor will sleep between accepts. This parameter (multiplicatively) reduce
# the sleep duration for each succesfull accept. (ie: 0.9 = reduce by 10%)
varnish_acceptor_sleep_decay: 0.900

# If we run out of resources, such as file descriptors or worker threads, the
# acceptor will sleep between accepts. This parameter control how much longer we
# sleep, each time we fail to accept a new connection.
varnish_acceptor_sleep_incr: 0.001

# If we run out of resources, such as file descriptors or worker threads, the
# acceptor will sleep between accepts. This parameter limits how long it can
# sleep between attempts to accept new connections.
varnish_acceptor_sleep_max: 0.050

# Restart child process automatically if it dies.
varnish_auto_restart: on

# Detect and eliminate duplicate bans.
varnish_ban_dups: on

# How long time does the ban lurker thread sleeps between successful attempts to
# push the last item up the ban list. It always sleeps a second when nothing can
# be done. A value of zero disables the ban lurker.
varnish_ban_lurker_sleep: 0.01

# Default timeout between bytes when receiving data from backend. We only wait
# for this many seconds between bytes before giving up. A value of 0 means it
# will never time out. VCL can override this default value for each backend
# request and backend request. This parameter does not apply to pipe.
varnish_between_bytes_timeout: 60

# Command used for compiling the C source code to a dlopen(3) loadable object.
# Any occurrence of %s in the string will be replaced with the source file name,
# and %o will be replaced with the output file name.
# varnish_cc_command: 'exec gcc -std=gnu99 -pthread -fpic -shared -Wl,-x -o %o %s'

# Size of buffer for CLI input. You may need to increase this if you have big
# VCL files and use the vcl.inline CLI command. NB: Must be specified with -p to
# have effect.
varnish_cli_buffer: 8192

# Timeout for the childs replies to CLI requests from the master.
varnish_cli_timeout: 10

# How much clockskew we are willing to accept between the backend and our own
# clock.
varnish_clock_skew: 10

# Default connection timeout for backend connections. We only try to connect to
# the backend for this many seconds before giving up. VCL can override this
# default value for each backend and backend request.
varnish_connect_timeout: 0.7

# How long time the critbit hasher keeps deleted objheads on the cooloff list.
varnish_critbit_cooloff: 180.0

# Default grace period. We will deliver an object this long after it has
# expired, provided another thread is attempting to get a new copy. Objects
# already cached will not be affected by changes made until they are fetched
# from the backend again.
varnish_default_grace: 10

# Default keep period. We will keep a useless object around this long, making it
# available for conditional backend fetches. That means that the object will be
# removed from the cache at the end of ttl+grace+keep.
varnish_default_keep: 0

# The TTL assigned to objects if neither the backend nor the VCL code assigns
# one. Objects already cached will not be affected by changes made until they
# are fetched from the backend again. To force an immediate effect at the
# expense of a total flush of the cache use "ban.url ."
varnish_default_ttl: 120

# Bitmap controlling diagnostics code:
#   - 0x00000001 - CNT_Session states.
#   - 0x00000002 - workspace debugging.
#   - 0x00000004 - kqueue debugging.
#   - 0x00000008 - mutex logging.
#   - 0x00000010 - mutex contests.
#   - 0x00000020 - waiting list.
#   - 0x00000040 - object workspace.
#   - 0x00001000 - do not core-dump child process.
#   - 0x00002000 - only short panic message.
#   - 0x00004000 - panic to stderr.
#   - 0x00010000 - synchronize shmlog.
#   - 0x00020000 - synchronous start of persistence.
#   - 0x00040000 - release VCL early.
#   - 0x00080000 - ban-lurker debugging.
#   - 0x80000000 - do edge-detection on digest.
# Use 0x notation and do the bitor in your head :-)
varnish_diag_bitmap: 0

# Bitmap controlling ESI parsing code:
#   - 0x00000001 - Don't check if it looks like XML
#   - 0x00000002 - Ignore non-esi elements
#   - 0x00000004 - Emit parsing debug records
#   - 0x00000008 - Force-split parser input (debugging)
# Use 0x notation and do the bitor in your head :-)
varnish_esi_syntax: 0

# How long the expiry thread sleeps when there is nothing for it to do.
varnish_expiry_sleep: 1

# The default chunksize used by fetcher. This should be bigger than the majority
# of objects with short TTLs. Internal limits in the storage_file module makes
# increases above 128kb a dubious idea.
varnish_fetch_chunksize: 128

# The maximum chunksize we attempt to allocate from storage. Making this too
# large may cause delays and storage fragmentation.
varnish_fetch_maxchunksize: 262144

# Default timeout for receiving first byte from backend. We only wait for this
# many seconds for the first byte before giving up. A value of 0 means it will
# never time out. VCL can override this default value for each backend and
# backend request. This parameter does not apply to pipe.
varnish_first_byte_timeout: 60

# Gzip compression level: 0=debug, 1=fast, 9=best
varnish_gzip_level: 6

# Gzip memory level 1=slow/least, 9=fast/most compression. Memory impact is
# 1=1k, 2=2k, ... 9=256k.
varnish_gzip_memlevel: 8

# Size of stack buffer used for gzip processing. The stack buffers are used for
# in-transit data, for instance gunzip'ed data being sent to a client.Making
# this space to small results in more overhead, writes to sockets etc, making it
# too big is probably just a waste of memory.
varnish_gzip_stack_buffer: 32768

# Where temporary space for gzip/gunzip is allocated:
#   0. malloc
#   1. session workspace
#   2. thread workspace
#
# If you have much gzip/gunzip activity, it may be an advantage to use workspace
# for these allocations to reduce malloc activity. Be aware that gzip needs
# 256+KB and gunzip needs 32+KB of workspace (64+KB if ESI processing).
varnish_gzip_tmp_space: 0

# Gzip window size 8=least, 15=most compression. Memory impact is 8=1k, 9=2k,
# ... 15=128k.
varnish_gzip_window: 15

# Enable gzip support. When enabled Varnish will compress uncompressed objects
# before they are stored in the cache. If a client does not support gzip
# encoding Varnish will uncompress compressed objects on demand. Varnish will
# also rewrite the Accept-Encoding header of clients indicating support for gz.
varnish_http_gzip_support: on

# Maximum number of HTTP headers we will deal with in client request or backend
# reponses. Note that the first line occupies five header fields. This paramter
# does not influence storage consumption, objects allocate exact space for the
# headers they store.
varnish_http_max_hdr: 64

# Enable support for HTTP Range headers.
varnish_http_range_support: on

# Maximum length of any HTTP client request header we will allow. The limit is
# inclusive its continuation lines.
varnish_http_req_hdr_len: 8192

# Maximum number of bytes of HTTP client request we will deal with. This is a
# limit on all bytes up to the double blank line which ends the HTTP request.
# The memory for the request is allocated from the session workspace (param:
# sess_workspace) and this parameter limits how much of that the request is
# allowed to take up.
varnish_http_req_size: 32768

# Maximum length of any HTTP backend response header we will allow. The limit is
# inclusive its continuation lines.
varnish_http_resp_hdr_len: 8192

# Maximum number of bytes of HTTP backend resonse we will deal with. This is a
# limit on all bytes up to the double blank line which ends the HTTP request.
# The memory for the request is allocated from the worker workspace (param:
# sess_workspace) and this parameter limits how much of that the request is
# allowed to take up.
varnish_http_resp_size: 32768

# Time to wait with no data sent. If no data has been transmitted in this many
# seconds the session is closed. See setsockopt(2) under SO_SNDTIMEO for more
# information.
varnish_idle_send_timeout: 60

# Listen queue depth.
varnish_listen_depth: 1024

# Grace period before object moves on LRU list. Objects are only moved to the
# front of the LRU list if they have not been moved there already inside this
# timeout period. This reduces the amount of lock operations necessary for LRU
# list access.
varnish_lru_interval: 2

# Maximum depth of esi:include processing.
varnish_max_esi_depth: 5

# Upper limit on how many times a request can restart. Be aware that restarts
# are likely to cause a hit against the backend, so don't increase
# thoughtlessly.
varnish_max_restarts: 4

# Maximum number of objects we attempt to nuke in orderto make space for a
# object body.
varnish_nuke_limit: 50

# The limit for the number of internal matching function calls in a pcre_exec()
# execution.
varnish_pcre_match_limit: 10000

# The limit for the number of internal matching function recursions in a
# pcre_exec() execution.
varnish_pcre_match_limit_recursion: 10000

# Interval between pings from parent to child. Zero will disable pinging
# entirely, which makes it possible to attach a debugger to the child.
varnish_ping_interval: 3

# Idle timeout for PIPE sessions. If nothing have been received in either
# direction for this many seconds, the session is closed.
varnish_pipe_timeout: 60

# Prefer IPv6 address when connecting to backends which have both IPv4 and IPv6
# addresses.
varnish_prefer_ipv6: off

# Percentage permitted queue length.
# This sets the ratio of queued requests to worker threads, above which sessions
# will be dropped instead of queued.
varnish_queue_max: 100

# How many parked request we start for each completed request on the object. NB:
# Even with the implict delay of delivery, this parameter controls an
# exponential increase in number of worker threads.
varnish_rush_exponent: 3

# The maximum number of objects held off by saint mode before no further will be
# made to the backend until one times out. A value of 0 disables saintmode.
varnish_saintmode_threshold: 10

# Send timeout for client connections. If the HTTP response hasn't been
# transmitted in this many seconds the session is closed. See setsockopt(2)
# under SO_SNDTIMEO for more information.
varnish_send_timeout: 600

# Idle timeout for persistent sessions. If a HTTP request has not been received
# in this many seconds, the session is closed.
varnish_sess_timeout: 5

# Bytes of HTTP protocol workspace allocated for sessions. This space must be
# big enough for the entire HTTP protocol header and any edits done to it in the
# VCL code. Minimum is 1024 bytes.
varnish_sess_workspace: 65536

# How long time the workerthread lingers on the session to see if a new request
# appears right away. If sessions are reused, as much as half of all reuses
# happen within the first 100 msec of the previous request completing. Setting
# this too high results in worker threads not doing anything for their keep,
# setting it too low just means that more sessions take a detour around the
# waiter.
varnish_session_linger: 50

# Maximum number of sessions we will allocate before just dropping connections.
# This is mostly an anti-DoS measure, and setting it plenty high should not
# hurt, as long as you have the memory for it.
varnish_session_max: 100000

# Objects created with TTL shorter than this are always put in transient
# storage.
varnish_shortlived: 10.0

# Wait at least this long between creating threads.
# Setting this too long results in insuffient worker threads.
# Setting this too short increases the risk of worker thread pile-up.
varnish_thread_pool_add_delay: 2

# Overflow threshold for worker thread creation.
# Setting this too low, will result in excess worker threads, which is generally
# a bad idea.
# Setting it too high results in insuffient worker threads.
varnish_thread_pool_add_threshold: 2

# Wait at least this long after a failed thread creation before trying to create
# another thread.
# Failure to create a worker thread is often a sign that the end is near,
# because the process is running out of RAM resources for thread stacks. This
# delay tries to not rush it on needlessly.
# If thread creation failures are a problem, check that thread_pool_max is not
# too high.
# It may also help to increase thread_pool_timeout and thread_pool_min, to
# reduce the rate at which treads are destroyed and later recreated.
varnish_thread_pool_fail_delay: 200

# The maximum number of worker threads in each pool.
# Do not set this higher than you have to, since excess worker threads soak up
# RAM and CPU and generally just get in the way of getting work done.
varnish_thread_pool_max: 500

# The minimum number of worker threads in each pool.
# Increasing this may help ramp up faster from low load situations where threads
# have expired.
# Minimum is 2 threads.
varnish_thread_pool_min: 5

# Wait this long between purging threads.
# This controls the decay of thread pools when idle(-ish).
# Minimum is 100 milliseconds.
varnish_thread_pool_purge_delay: 1000

# Worker thread stack size. On 32bit systems you may need to tweak this down to
# fit many threads into the limited address space.
varnish_thread_pool_stack: -1

# Thread idle threshold.
# Threads in excess of thread_pool_min, which have been idle for at least this
# long are candidates for purging.
# Minimum is 1 second.
varnish_thread_pool_timeout: 300

# Bytes of HTTP protocol workspace allocated for worker threads. This space must
# be big enough for the backend request and responses, and response to the
# client plus any other memory needs in the VCL code.Minimum is 1024 bytes.
varnish_thread_pool_workspace: 65536

# Number of worker thread pools.
# Increasing number of worker pools decreases lock contention.
# Too many pools waste CPU and RAM resources, and more than one pool for each
# CPU is probably detrimal to performance.
# Can be increased on the fly, but decreases require a restart to take effect.
varnish_thread_pools:
varnish_thread_pools_per_core: 2

# Worker threads accumulate statistics, and dump these into the global stats
# counters if the lock is free when they finish a request. This parameters
# defines the maximum number of requests a worker thread may handle, before it
# is forced to dump its accumulated stats into the global counters.
varnish_thread_stats_rate: 10

# Unreferenced VCL objects result in error.
varnish_vcc_err_unref: on

# Select the waiter kernel interface.
varnish_waiter: default
